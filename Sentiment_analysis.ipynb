{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Nhận dạng bình luận tiêu cực </h1>\n",
        "<h4> Trong notebook này, chúng ta sẽ: <h4>\n",
        "<ul>\n",
        "  <li> Tìm hiểu sơ bộ về Tiếng Việt </li>\n",
        "  <li> Tìm hiểu về cách tiền xử lý thông tin dạng chuỗi (string) </li>\n",
        "  <li> Vector hóa chuỗi\n",
        "  <li> Xây dựng mô hình đoán nhận bình luận tiêu cực sử dụng Keras, khám phá mô hình LSTM </li>\n",
        "</ul>\n",
        "\n",
        "<p> Xin cảm ơn rất nhiều vì những kiến thức mà anh Trần Công Nghĩa và anh Lê Quốc Hưng đã chia sẻ thông qua blog streetcodevn.com </p> \n",
        "<p> My heroes <3 </p>"
      ],
      "metadata": {
        "id": "31m_4XfgkP3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Sơ bộ </h1>\n",
        "<p> Phát biểu theo góc nhìn của máy học (Machine Learning) thì nhận dạng bình luận tiêu cực là bài toán phân lớp cảm xúc dựa trên văn bản ngôn ngữ tự nhiên. Đầu vào của bài toán là một câu hay một đoạn văn bản, còn đầu ra là các giá trị xác suất (điểm số) của N lớp cảm xúc mà ta cần xác định. </p>\n",
        "<p> "
      ],
      "metadata": {
        "id": "FoSv0_RyvQFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> 1. Tìm hiểu sơ bộ về tiếng Việt </h3>\n",
        "<p> Trước hết, chúng ta cần biết một số điều về tiếng Việt: </p>\n",
        "<p> Đầu tiên, tiếng Việt có tính chất đơn lập. Tính đơn lập này được thể hiện đầu tiên qua việc các từ của tiếng Việt thường chỉ bao gồm từ một đến 2 tiếng. Điều này đồng nghĩa với việc tỉ lệ tiếng trên từ của tiếng Việt khá thấp, gần bằng 1.\n",
        "<p> Tiếp theo, tính chất đơn lập được thể hiện qua việc tiếng Việt không có khái niệm chia dạng từ (conjugation). Trong tiếng Anh, chúng ta có thể biểu diễn thì của tiếng Anh thông qua cách chia động từ: to dream (nguyên thể) dream/dreams (thể trần thuật) -> dream (thể giả định) -> dreaming (phân từ I) -> dreamed (thể quá khứ) -> dreamt (thể phân từ II),...\n",
        "<p> Thế nhưng, trong tiếng Việt, hư từ và vị trí, trật tự từ đóng vai trò làm rõ quan hệ ngữ pháp cũng như ý nghĩa ngữ pháp của từ và của câu. Với cùng ví dụ đó, ta có thể biểu diễn thì của hành động trong câu thông qua các bổ ngữ, như đã, đang, sẽ, đã từng,...\n",
        "<p> Một điểm đặc trưng nữa là tính hình tiết; hạt nhân cơ bản của từ vựng là các từ đơn tiết. Vì thế mà ranh giới giữa âm tiết, tiếng và từ không rõ ràng (ví dụ: trong tiếng Việt, \"nhà\" vừa là một tiếng, mà cũng vừa là một từ). Cũng vì vậy mà từ ghép và cụm từ cũng khó phân biệt. Đặc biệt, chúng ta còn có các khái niệm như từ ghép đẳng lập, từ ghép chính phụ, từ láy, các tiếng trong từ có thể có mối quan hệ về nghĩa (như từ ghép) hay mối quan hệ về âm (như từ láy). Đặc biệt, với từ láy, có thể được tạo bởi 2 đến 3 tiếng nhưng bắt buộc nhiều nhất một từ có ý nghĩa.\n",
        "<p> Cuối cùng, khái niệm \"các từ loại\" là rất mơ hồ. Ví dụ: \"cưa\" vừa là dụng cụ để xẻ gỗ, vừa chỉ hành động cắt xẻ gỗ. Nguyên nhân do cấu trúc của những từ có ý nghĩa đối tượng, tính chất, hành động,...không tách biệt nhau.\n",
        "\n",
        "<p> Các tính chất này của tiếng Việt sẽ có ảnh hưởng sâu sắc tới cách chúng ta xử lý dữ liệu đầu vào."
      ],
      "metadata": {
        "id": "BzscULH6oO8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p> Chúng ta hãy cũng nhìn vào các công việc thông thường khi xử lý dữ liệu đầu vào với ngôn ngữ tiếng Anh: </p>\n",
        "<ol>\n",
        "  <li> Loại bỏ các ký tự không phải dạng ký tự (eg. Các dấu câu)\n",
        "  <li> Chuyển các kí tự thành dạng chữ cái thường\n",
        "  <li> Chuyển các câu thành danh sách các từ (Tokenization)\n",
        "  <li> Loại bỏ các hư từ (stop-words)\n",
        "  <li> Cắt từ (Stemming) hoặc tìm gốc từ (Lemmatization)\n",
        "  <li> Chuyển các từ thành tensors (Vectorization)\n",
        "</ol>\n",
        "\n",
        "<p> Trong các công đoạn trên, chỉ có công đoạn thứ 5 chúng ta cần làm khác so với tiếng Anh. Do tiếng Việt có bản chất monosyllabic, quá trình tách từ sẽ được thực hiện qua việc nối tiếng (bằng dấu '_' theo ý nghĩa) và tách tiếng (thông qua dấu ' ')"
      ],
      "metadata": {
        "id": "dXFUkXXG0joO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import string\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rstjmnTLY1oH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1979a84e-0245-4b1d-d01f-d658981125e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p> Chúng ta sẽ không tách từ dựa trên các dấu cách (như tiếng Anh) mà sẽ tách từ dựa trên ý nghĩa. Đây là một công việc rất khó, và chúng ta sẽ sử dụng công trình nghiên cứu của Nguyen. Dat, Nguyen. Dai, Dras. Mark, Johnson. Mark. Phần mềm của họ được viết trong ngôn ngữ Java, nên ta sẽ sử dụng implementation của Pham. Vinh, được viết bằng ngôn ngữ Python."
      ],
      "metadata": {
        "id": "AqYNc0cv4LnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Sudo-VP/Vietnamese-Word-Segmentation-Python.git"
      ],
      "metadata": {
        "id": "DlqZas-wI4SI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9ba5d3-ad81-4834-efe9-344cca200e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Vietnamese-Word-Segmentation-Python'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 118 (delta 33), reused 96 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (118/118), 905.21 KiB | 5.00 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/Vietnamese-Word-Segmentation-Python\"\n",
        "!python setup.py install\n",
        "!python -m pip install ."
      ],
      "metadata": {
        "id": "GbvQlhiYdI2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48d3801-b618-4afb-8a6a-4416df2b2bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: vws\n",
            "  Building wheel for vws (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vws: filename=vws-0.0.1-py3-none-any.whl size=554050 sha256=0e8ef634975939f87ef4b9880880d3fb6b82ed5c4c98033e7071fc814ac8e90e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/88/2a/869ab89724061d03607181dd71071221ebb4df266644839a12\n",
            "Successfully built vws\n",
            "Installing collected packages: vws\n",
            "  Attempting uninstall: vws\n",
            "    Found existing installation: vws 0.0.1\n",
            "    Uninstalling vws-0.0.1:\n",
            "      Successfully uninstalled vws-0.0.1\n",
            "Successfully installed vws-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vws import RDRSegmenter, Tokenizer\n",
        "rdrsegment = RDRSegmenter.RDRSegmenter()\n",
        "tokenizer = Tokenizer.Tokenizer()"
      ],
      "metadata": {
        "id": "rsKbqbxofFbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hàm get_paths() được sử dụng để lấy đường dẫn của tất cả các file có đuôi .txt. Hàm load_text() được sử dụng để đọc file và trả về nội dung file dưới dạng các string."
      ],
      "metadata": {
        "id": "dDr-7KSU4PWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def get_paths(PATH):\n",
        "  paths = []\n",
        "  for root, subFolder, files in os.walk(PATH):\n",
        "      for item in files:\n",
        "          if item.endswith(\".txt\") :\n",
        "              fileNamePath = str(os.path.join(root,item))\n",
        "              paths.append(fileNamePath)\n",
        "  return paths"
      ],
      "metadata": {
        "id": "CxPtSFHRw4Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_text(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text"
      ],
      "metadata": {
        "id": "QOUNvi3g1SFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ở bên dưới, ta đang load danh sách các hư từ từ một file txt. File txt này là kết quả của Le. Duyet, các bạn có thể tải từ trang web https://github.com/stopwords/vietnamese-stopwords"
      ],
      "metadata": {
        "id": "qfI-pfOL4p5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = load_text(\"/content/drive/MyDrive/Dataset_Sentiment_Analysis/stop_words/vietnamese-stopwords-dash.txt\")\n",
        "stop_words = stop_words.split()"
      ],
      "metadata": {
        "id": "3Yfw1zw4C1uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nkh2t7d8Xnf",
        "outputId": "210da1cc-c2dd-42a0-b5db-e39cd556d3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh', 'anh_ấy', 'ba', 'ba_ba', 'ba_bản', 'ba_cùng', 'ba_họ', 'ba_ngày', 'ba_ngôi', 'ba_tăng', 'bao_giờ', 'bao_lâu', 'bao_nhiêu', 'bao_nả', 'bay_biến', 'biết', 'biết_bao', 'biết_bao_nhiêu', 'biết_chắc', 'biết_chừng_nào', 'biết_mình', 'biết_mấy', 'biết_thế', 'biết_trước', 'biết_việc', 'biết_đâu', 'biết_đâu_chừng', 'biết_đâu_đấy', 'biết_được', 'buổi', 'buổi_làm', 'buổi_mới', 'buổi_ngày', 'buổi_sớm', 'bà', 'bà_ấy', 'bài', 'bài_bác', 'bài_bỏ', 'bài_cái', 'bác', 'bán', 'bán_cấp', 'bán_dạ', 'bán_thế', 'bây_bẩy', 'bây_chừ', 'bây_giờ', 'bây_nhiêu', 'bèn', 'béng', 'bên', 'bên_bị', 'bên_có', 'bên_cạnh', 'bông', 'bước', 'bước_khỏi', 'bước_tới', 'bước_đi', 'bạn', 'bản', 'bản_bộ', 'bản_riêng', 'bản_thân', 'bản_ý', 'bất_chợt', 'bất_cứ', 'bất_giác', 'bất_kì', 'bất_kể', 'bất_kỳ', 'bất_luận', 'bất_ngờ', 'bất_nhược', 'bất_quá', 'bất_quá_chỉ', 'bất_thình_lình', 'bất_tử', 'bất_đồ', 'bấy', 'bấy_chầy', 'bấy_chừ', 'bấy_giờ', 'bấy_lâu', 'bấy_lâu_nay', 'bấy_nay', 'bấy_nhiêu', 'bập_bà_bập_bõm', 'bập_bõm', 'bắt_đầu', 'bắt_đầu_từ', 'bằng', 'bằng_cứ', 'bằng_không', 'bằng_người', 'bằng_nhau', 'bằng_như', 'bằng_nào', 'bằng_nấy', 'bằng_vào', 'bằng_được', 'bằng_ấy', 'bển', 'bệt', 'bị', 'bị_chú', 'bị_vì', 'bỏ', 'bỏ_bà', 'bỏ_cha', 'bỏ_cuộc', 'bỏ_không', 'bỏ_lại', 'bỏ_mình', 'bỏ_mất', 'bỏ_mẹ', 'bỏ_nhỏ', 'bỏ_quá', 'bỏ_ra', 'bỏ_riêng', 'bỏ_việc', 'bỏ_xa', 'bỗng', 'bỗng_chốc', 'bỗng_dưng', 'bỗng_không', 'bỗng_nhiên', 'bỗng_nhưng', 'bỗng_thấy', 'bỗng_đâu', 'bộ', 'bộ_thuộc', 'bộ_điều', 'bội_phần', 'bớ', 'bởi', 'bởi_ai', 'bởi_chưng', 'bởi_nhưng', 'bởi_sao', 'bởi_thế', 'bởi_thế_cho_nên', 'bởi_tại', 'bởi_vì', 'bởi_vậy', 'bởi_đâu', 'bức', 'cao', 'cao_lâu', 'cao_ráo', 'cao_răng', 'cao_sang', 'cao_số', 'cao_thấp', 'cao_thế', 'cao_xa', 'cha', 'cha_chả', 'chao_ôi', 'chia_sẻ', 'chiếc', 'cho', 'cho_biết', 'cho_chắc', 'cho_hay', 'cho_nhau', 'cho_nên', 'cho_rằng', 'cho_rồi', 'cho_thấy', 'cho_tin', 'cho_tới', 'cho_tới_khi', 'cho_về', 'cho_ăn', 'cho_đang', 'cho_được', 'cho_đến', 'cho_đến_khi', 'cho_đến_nỗi', 'choa', 'chu_cha', 'chui_cha', 'chung', 'chung_cho', 'chung_chung', 'chung_cuộc', 'chung_cục', 'chung_nhau', 'chung_qui', 'chung_quy', 'chung_quy_lại', 'chung_ái', 'chuyển', 'chuyển_tự', 'chuyển_đạt', 'chuyện', 'chuẩn_bị', 'chành_chạnh', 'chí_chết', 'chính', 'chính_bản', 'chính_giữa', 'chính_là', 'chính_thị', 'chính_điểm', 'chùn_chùn', 'chùn_chũn', 'chú', 'chú_dẫn', 'chú_khách', 'chú_mày', 'chú_mình', 'chúng', 'chúng_mình', 'chúng_ta', 'chúng_tôi', 'chúng_ông', 'chăn_chắn', 'chăng', 'chăng_chắc', 'chăng_nữa', 'chơi', 'chơi_họ', 'chưa', 'chưa_bao_giờ', 'chưa_chắc', 'chưa_có', 'chưa_cần', 'chưa_dùng', 'chưa_dễ', 'chưa_kể', 'chưa_tính', 'chưa_từng', 'chầm_chập', 'chậc', 'chắc', 'chắc_chắn', 'chắc_dạ', 'chắc_hẳn', 'chắc_lòng', 'chắc_người', 'chắc_vào', 'chắc_ăn', 'chẳng_lẽ', 'chẳng_những', 'chẳng_nữa', 'chẳng_phải', 'chết_nỗi', 'chết_thật', 'chết_tiệt', 'chỉ', 'chỉ_chính', 'chỉ_có', 'chỉ_là', 'chỉ_tên', 'chỉn', 'chị', 'chị_bộ', 'chị_ấy', 'chịu', 'chịu_chưa', 'chịu_lời', 'chịu_tốt', 'chịu_ăn', 'chọn', 'chọn_bên', 'chọn_ra', 'chốc_chốc', 'chớ', 'chớ_chi', 'chớ_gì', 'chớ_không', 'chớ_kể', 'chớ_như', 'chợt', 'chợt_nghe', 'chợt_nhìn', 'chủn', 'chứ', 'chứ_ai', 'chứ_còn', 'chứ_gì', 'chứ_không', 'chứ_không_phải', 'chứ_lại', 'chứ_lị', 'chứ_như', 'chứ_sao', 'coi_bộ', 'coi_mòi', 'con', 'con_con', 'con_dạ', 'con_nhà', 'con_tính', 'cu_cậu', 'cuối', 'cuối_cùng', 'cuối_điểm', 'cuốn', 'cuộc', 'càng', 'càng_càng', 'càng_hay', 'cá_nhân', 'các', 'các_cậu', 'cách', 'cách_bức', 'cách_không', 'cách_nhau', 'cách_đều', 'cái', 'cái_gì', 'cái_họ', 'cái_đã', 'cái_đó', 'cái_ấy', 'câu_hỏi', 'cây', 'cây_nước', 'còn', 'còn_như', 'còn_nữa', 'còn_thời_gian', 'còn_về', 'có', 'có_ai', 'có_chuyện', 'có_chăng', 'có_chăng_là', 'có_chứ', 'có_cơ', 'có_dễ', 'có_họ', 'có_khi', 'có_ngày', 'có_người', 'có_nhiều', 'có_nhà', 'có_phải', 'có_số', 'có_tháng', 'có_thế', 'có_thể', 'có_vẻ', 'có_ý', 'có_ăn', 'có_điều', 'có_điều_kiện', 'có_đáng', 'có_đâu', 'có_được', 'cóc_khô', 'cô', 'cô_mình', 'cô_quả', 'cô_tăng', 'cô_ấy', 'công_nhiên', 'cùng', 'cùng_chung', 'cùng_cực', 'cùng_nhau', 'cùng_tuổi', 'cùng_tột', 'cùng_với', 'cùng_ăn', 'căn', 'căn_cái', 'căn_cắt', 'căn_tính', 'cũng', 'cũng_như', 'cũng_nên', 'cũng_thế', 'cũng_vậy', 'cũng_vậy_thôi', 'cũng_được', 'cơ', 'cơ_chỉ', 'cơ_chừng', 'cơ_cùng', 'cơ_dẫn', 'cơ_hồ', 'cơ_hội', 'cơ_mà', 'cơn', 'cả', 'cả_nghe', 'cả_nghĩ', 'cả_ngày', 'cả_người', 'cả_nhà', 'cả_năm', 'cả_thảy', 'cả_thể', 'cả_tin', 'cả_ăn', 'cả_đến', 'cảm_thấy', 'cảm_ơn', 'cấp', 'cấp_số', 'cấp_trực_tiếp', 'cần', 'cần_cấp', 'cần_gì', 'cần_số', 'cật_lực', 'cật_sức', 'cậu', 'cổ_lai', 'cụ_thể', 'cụ_thể_là', 'cụ_thể_như', 'của', 'của_ngọt', 'của_tin', 'cứ', 'cứ_như', 'cứ_việc', 'cứ_điểm', 'cực_lực', 'do', 'do_vì', 'do_vậy', 'do_đó', 'duy', 'duy_chỉ', 'duy_có', 'dài', 'dài_lời', 'dài_ra', 'dành', 'dành_dành', 'dào', 'dì', 'dù', 'dù_cho', 'dù_dì', 'dù_gì', 'dù_rằng', 'dù_sao', 'dùng', 'dùng_cho', 'dùng_hết', 'dùng_làm', 'dùng_đến', 'dưới', 'dưới_nước', 'dạ', 'dạ_bán', 'dạ_con', 'dạ_dài', 'dạ_dạ', 'dạ_khách', 'dần_dà', 'dần_dần', 'dầu_sao', 'dẫn', 'dẫu', 'dẫu_mà', 'dẫu_rằng', 'dẫu_sao', 'dễ', 'dễ_dùng', 'dễ_gì', 'dễ_khiến', 'dễ_nghe', 'dễ_ngươi', 'dễ_như_chơi', 'dễ_sợ', 'dễ_sử_dụng', 'dễ_thường', 'dễ_thấy', 'dễ_ăn', 'dễ_đâu', 'dở_chừng', 'dữ', 'dữ_cách', 'em', 'em_em', 'giá_trị', 'giá_trị_thực_tế', 'giảm', 'giảm_chính', 'giảm_thấp', 'giảm_thế', 'giống', 'giống_người', 'giống_nhau', 'giống_như', 'giờ', 'giờ_lâu', 'giờ_này', 'giờ_đi', 'giờ_đây', 'giờ_đến', 'giữ', 'giữ_lấy', 'giữ_ý', 'giữa', 'giữa_lúc', 'gây', 'gây_cho', 'gây_giống', 'gây_ra', 'gây_thêm', 'gì', 'gì_gì', 'gì_đó', 'gần', 'gần_bên', 'gần_hết', 'gần_ngày', 'gần_như', 'gần_xa', 'gần_đây', 'gần_đến', 'gặp', 'gặp_khó_khăn', 'gặp_phải', 'gồm', 'hay', 'hay_biết', 'hay_hay', 'hay_không', 'hay_là', 'hay_làm', 'hay_nhỉ', 'hay_nói', 'hay_sao', 'hay_tin', 'hay_đâu', 'hiểu', 'hiện_nay', 'hiện_tại', 'hoàn_toàn', 'hoặc', 'hoặc_là', 'hãy', 'hãy_còn', 'hơn', 'hơn_cả', 'hơn_hết', 'hơn_là', 'hơn_nữa', 'hơn_trước', 'hầu_hết', 'hết', 'hết_chuyện', 'hết_cả', 'hết_của', 'hết_nói', 'hết_ráo', 'hết_rồi', 'hết_ý', 'họ', 'họ_gần', 'họ_xa', 'hỏi', 'hỏi_lại', 'hỏi_xem', 'hỏi_xin', 'hỗ_trợ', 'khi', 'khi_khác', 'khi_không', 'khi_nào', 'khi_nên', 'khi_trước', 'khiến', 'khoảng', 'khoảng_cách', 'khoảng_không', 'khá', 'khá_tốt', 'khác', 'khác_gì', 'khác_khác', 'khác_nhau', 'khác_nào', 'khác_thường', 'khác_xa', 'khách', 'khó', 'khó_biết', 'khó_chơi', 'khó_khăn', 'khó_làm', 'khó_mở', 'khó_nghe', 'khó_nghĩ', 'khó_nói', 'khó_thấy', 'khó_tránh', 'không', 'không_ai', 'không_bao_giờ', 'không_bao_lâu', 'không_biết', 'không_bán', 'không_chỉ', 'không_còn', 'không_có', 'không_có_gì', 'không_cùng', 'không_cần', 'không_cứ', 'không_dùng', 'không_gì', 'không_hay', 'không_khỏi', 'không_kể', 'không_ngoài', 'không_nhận', 'không_những', 'không_phải', 'không_phải_không', 'không_thể', 'không_tính', 'không_điều_kiện', 'không_được', 'không_đầy', 'không_để', 'khẳng_định', 'khỏi', 'khỏi_nói', 'kể', 'kể_cả', 'kể_như', 'kể_tới', 'kể_từ', 'liên_quan', 'loại', 'loại_từ', 'luôn', 'luôn_cả', 'luôn_luôn', 'luôn_tay', 'là', 'là_cùng', 'là_là', 'là_nhiều', 'là_phải', 'là_thế_nào', 'là_vì', 'là_ít', 'làm', 'làm_bằng', 'làm_cho', 'làm_dần_dần', 'làm_gì', 'làm_lòng', 'làm_lại', 'làm_lấy', 'làm_mất', 'làm_ngay', 'làm_như', 'làm_nên', 'làm_ra', 'làm_riêng', 'làm_sao', 'làm_theo', 'làm_thế_nào', 'làm_tin', 'làm_tôi', 'làm_tăng', 'làm_tại', 'làm_tắp_lự', 'làm_vì', 'làm_đúng', 'làm_được', 'lâu', 'lâu_các', 'lâu_lâu', 'lâu_nay', 'lâu_ngày', 'lên', 'lên_cao', 'lên_cơn', 'lên_mạnh', 'lên_ngôi', 'lên_nước', 'lên_số', 'lên_xuống', 'lên_đến', 'lòng', 'lòng_không', 'lúc', 'lúc_khác', 'lúc_lâu', 'lúc_nào', 'lúc_này', 'lúc_sáng', 'lúc_trước', 'lúc_đi', 'lúc_đó', 'lúc_đến', 'lúc_ấy', 'lý_do', 'lượng', 'lượng_cả', 'lượng_số', 'lượng_từ', 'lại', 'lại_bộ', 'lại_cái', 'lại_còn', 'lại_giống', 'lại_làm', 'lại_người', 'lại_nói', 'lại_nữa', 'lại_quả', 'lại_thôi', 'lại_ăn', 'lại_đây', 'lấy', 'lấy_có', 'lấy_cả', 'lấy_giống', 'lấy_làm', 'lấy_lý_do', 'lấy_lại', 'lấy_ra', 'lấy_ráo', 'lấy_sau', 'lấy_số', 'lấy_thêm', 'lấy_thế', 'lấy_vào', 'lấy_xuống', 'lấy_được', 'lấy_để', 'lần', 'lần_khác', 'lần_lần', 'lần_nào', 'lần_này', 'lần_sang', 'lần_sau', 'lần_theo', 'lần_trước', 'lần_tìm', 'lớn', 'lớn_lên', 'lớn_nhỏ', 'lời', 'lời_chú', 'lời_nói', 'mang', 'mang_lại', 'mang_mang', 'mang_nặng', 'mang_về', 'muốn', 'mà', 'mà_cả', 'mà_không', 'mà_lại', 'mà_thôi', 'mà_vẫn', 'mình', 'mạnh', 'mất', 'mất_còn', 'mọi', 'mọi_giờ', 'mọi_khi', 'mọi_lúc', 'mọi_người', 'mọi_nơi', 'mọi_sự', 'mọi_thứ', 'mọi_việc', 'mối', 'mỗi', 'mỗi_lúc', 'mỗi_lần', 'mỗi_một', 'mỗi_ngày', 'mỗi_người', 'một', 'một_cách', 'một_cơn', 'một_khi', 'một_lúc', 'một_số', 'một_vài', 'một_ít', 'mới', 'mới_hay', 'mới_rồi', 'mới_đây', 'mở', 'mở_mang', 'mở_nước', 'mở_ra', 'mợ', 'mức', 'nay', 'ngay', 'ngay_bây_giờ', 'ngay_cả', 'ngay_khi', 'ngay_khi_đến', 'ngay_lúc', 'ngay_lúc_này', 'ngay_lập_tức', 'ngay_thật', 'ngay_tức_khắc', 'ngay_tức_thì', 'ngay_từ', 'nghe', 'nghe_chừng', 'nghe_hiểu', 'nghe_không', 'nghe_lại', 'nghe_nhìn', 'nghe_như', 'nghe_nói', 'nghe_ra', 'nghe_rõ', 'nghe_thấy', 'nghe_tin', 'nghe_trực_tiếp', 'nghe_đâu', 'nghe_đâu_như', 'nghe_được', 'nghen', 'nghiễm_nhiên', 'nghĩ', 'nghĩ_lại', 'nghĩ_ra', 'nghĩ_tới', 'nghĩ_xa', 'nghĩ_đến', 'nghỉm', 'ngoài', 'ngoài_này', 'ngoài_ra', 'ngoài_xa', 'ngoải', 'nguồn', 'ngày', 'ngày_càng', 'ngày_cấp', 'ngày_giờ', 'ngày_ngày', 'ngày_nào', 'ngày_này', 'ngày_nọ', 'ngày_qua', 'ngày_rày', 'ngày_tháng', 'ngày_xưa', 'ngày_xửa', 'ngày_đến', 'ngày_ấy', 'ngôi', 'ngôi_nhà', 'ngôi_thứ', 'ngõ_hầu', 'ngăn_ngắt', 'ngươi', 'người', 'người_hỏi', 'người_khác', 'người_khách', 'người_mình', 'người_nghe', 'người_người', 'người_nhận', 'ngọn', 'ngọn_nguồn', 'ngọt', 'ngồi', 'ngồi_bệt', 'ngồi_không', 'ngồi_sau', 'ngồi_trệt', 'ngộ_nhỡ', 'nhanh', 'nhanh_lên', 'nhanh_tay', 'nhau', 'nhiên_hậu', 'nhiều', 'nhiều_ít', 'nhiệt_liệt', 'nhung_nhăng', 'nhà', 'nhà_chung', 'nhà_khó', 'nhà_làm', 'nhà_ngoài', 'nhà_ngươi', 'nhà_tôi', 'nhà_việc', 'nhân_dịp', 'nhân_tiện', 'nhé', 'nhìn', 'nhìn_chung', 'nhìn_lại', 'nhìn_nhận', 'nhìn_theo', 'nhìn_thấy', 'nhìn_xuống', 'nhóm', 'nhón_nhén', 'như', 'như_ai', 'như_chơi', 'như_không', 'như_là', 'như_nhau', 'như_quả', 'như_sau', 'như_thường', 'như_thế', 'như_thế_nào', 'như_thể', 'như_trên', 'như_trước', 'như_tuồng', 'như_vậy', 'như_ý', 'nhưng', 'nhưng_mà', 'nhược_bằng', 'nhất', 'nhất_loạt', 'nhất_luật', 'nhất_là', 'nhất_mực', 'nhất_nhất', 'nhất_quyết', 'nhất_sinh', 'nhất_thiết', 'nhất_thì', 'nhất_tâm', 'nhất_tề', 'nhất_đán', 'nhất_định', 'nhận', 'nhận_biết', 'nhận_họ', 'nhận_làm', 'nhận_nhau', 'nhận_ra', 'nhận_thấy', 'nhận_việc', 'nhận_được', 'nhằm', 'nhằm_khi', 'nhằm_lúc', 'nhằm_vào', 'nhằm_để', 'nhỉ', 'nhỏ', 'nhỏ_người', 'nhớ', 'nhớ_bập_bõm', 'nhớ_lại', 'nhớ_lấy', 'nhớ_ra', 'nhờ', 'nhờ_chuyển', 'nhờ_có', 'nhờ_nhờ', 'nhờ_đó', 'nhỡ_ra', 'những', 'những_ai', 'những_khi', 'những_là', 'những_lúc', 'những_muốn', 'những_như', 'nào', 'nào_cũng', 'nào_hay', 'nào_là', 'nào_phải', 'nào_đâu', 'nào_đó', 'này', 'này_nọ', 'nên', 'nên_chi', 'nên_chăng', 'nên_làm', 'nên_người', 'nên_tránh', 'nó', 'nóc', 'nói', 'nói_bông', 'nói_chung', 'nói_khó', 'nói_là', 'nói_lên', 'nói_lại', 'nói_nhỏ', 'nói_phải', 'nói_qua', 'nói_ra', 'nói_riêng', 'nói_rõ', 'nói_thêm', 'nói_thật', 'nói_toẹt', 'nói_trước', 'nói_tốt', 'nói_với', 'nói_xa', 'nói_ý', 'nói_đến', 'nói_đủ', 'năm', 'năm_tháng', 'nơi', 'nơi_nơi', 'nước', 'nước_bài', 'nước_cùng', 'nước_lên', 'nước_nặng', 'nước_quả', 'nước_xuống', 'nước_ăn', 'nước_đến', 'nấy', 'nặng', 'nặng_căn', 'nặng_mình', 'nặng_về', 'nếu', 'nếu_có', 'nếu_cần', 'nếu_không', 'nếu_mà', 'nếu_như', 'nếu_thế', 'nếu_vậy', 'nếu_được', 'nền', 'nọ', 'nớ', 'nức_nở', 'nữa', 'nữa_khi', 'nữa_là', 'nữa_rồi', 'oai_oái', 'oái', 'pho', 'phè', 'phè_phè', 'phía', 'phía_bên', 'phía_bạn', 'phía_dưới', 'phía_sau', 'phía_trong', 'phía_trên', 'phía_trước', 'phóc', 'phót', 'phù_hợp', 'phăn_phắt', 'phương_chi', 'phải', 'phải_biết', 'phải_chi', 'phải_chăng', 'phải_cách', 'phải_cái', 'phải_giờ', 'phải_khi', 'phải_không', 'phải_lại', 'phải_lời', 'phải_người', 'phải_như', 'phải_rồi', 'phải_tay', 'phần', 'phần_lớn', 'phần_nhiều', 'phần_nào', 'phần_sau', 'phần_việc', 'phắt', 'phỉ_phui', 'phỏng', 'phỏng_như', 'phỏng_nước', 'phỏng_theo', 'phỏng_tính', 'phốc', 'phụt', 'phứt', 'qua', 'qua_chuyện', 'qua_khỏi', 'qua_lại', 'qua_lần', 'qua_ngày', 'qua_tay', 'qua_thì', 'qua_đi', 'quan_trọng', 'quan_trọng_vấn_đề', 'quan_tâm', 'quay', 'quay_bước', 'quay_lại', 'quay_số', 'quay_đi', 'quá', 'quá_bán', 'quá_bộ', 'quá_giờ', 'quá_lời', 'quá_mức', 'quá_nhiều', 'quá_tay', 'quá_thì', 'quá_tin', 'quá_trình', 'quá_tuổi', 'quá_đáng', 'quá_ư', 'quả', 'quả_là', 'quả_thật', 'quả_thế', 'quả_vậy', 'quận', 'ra', 'ra_bài', 'ra_bộ', 'ra_chơi', 'ra_gì', 'ra_lại', 'ra_lời', 'ra_ngôi', 'ra_người', 'ra_sao', 'ra_tay', 'ra_vào', 'ra_ý', 'ra_điều', 'ra_đây', 'ren_rén', 'riu_ríu', 'riêng', 'riêng_từng', 'riệt', 'rày', 'ráo', 'ráo_cả', 'ráo_nước', 'ráo_trọi', 'rén', 'rén_bước', 'rích', 'rón_rén', 'rõ', 'rõ_là', 'rõ_thật', 'rút_cục', 'răng', 'răng_răng', 'rất', 'rất_lâu', 'rằng', 'rằng_là', 'rốt_cuộc', 'rốt_cục', 'rồi', 'rồi_nữa', 'rồi_ra', 'rồi_sao', 'rồi_sau', 'rồi_tay', 'rồi_thì', 'rồi_xem', 'rồi_đây', 'rứa', 'sa_sả', 'sang', 'sang_năm', 'sang_sáng', 'sang_tay', 'sao', 'sao_bản', 'sao_bằng', 'sao_cho', 'sao_vậy', 'sao_đang', 'sau', 'sau_chót', 'sau_cuối', 'sau_cùng', 'sau_hết', 'sau_này', 'sau_nữa', 'sau_sau', 'sau_đây', 'sau_đó', 'so', 'so_với', 'song_le', 'suýt', 'suýt_nữa', 'sáng', 'sáng_ngày', 'sáng_rõ', 'sáng_thế', 'sáng_ý', 'sì', 'sì_sì', 'sất', 'sắp', 'sắp_đặt', 'sẽ', 'sẽ_biết', 'sẽ_hay', 'số', 'số_cho_biết', 'số_cụ_thể', 'số_loại', 'số_là', 'số_người', 'số_phần', 'số_thiếu', 'sốt_sột', 'sớm', 'sớm_ngày', 'sở_dĩ', 'sử_dụng', 'sự', 'sự_thế', 'sự_việc', 'tanh', 'tanh_tanh', 'tay', 'tay_quay', 'tha_hồ', 'tha_hồ_chơi', 'tha_hồ_ăn', 'than_ôi', 'thanh', 'thanh_ba', 'thanh_chuyển', 'thanh_không', 'thanh_thanh', 'thanh_tính', 'thanh_điều_kiện', 'thanh_điểm', 'thay_đổi', 'thay_đổi_tình_trạng', 'theo', 'theo_bước', 'theo_như', 'theo_tin', 'thi_thoảng', 'thiếu', 'thiếu_gì', 'thiếu_điểm', 'thoạt', 'thoạt_nghe', 'thoạt_nhiên', 'thoắt', 'thuần', 'thuần_ái', 'thuộc', 'thuộc_bài', 'thuộc_cách', 'thuộc_lại', 'thuộc_từ', 'thà', 'thà_là', 'thà_rằng', 'thành_ra', 'thành_thử', 'thái_quá', 'tháng', 'tháng_ngày', 'tháng_năm', 'tháng_tháng', 'thêm', 'thêm_chuyện', 'thêm_giờ', 'thêm_vào', 'thì', 'thì_giờ', 'thì_là', 'thì_phải', 'thì_ra', 'thì_thôi', 'thình_lình', 'thích', 'thích_cứ', 'thích_thuộc', 'thích_tự', 'thích_ý', 'thím', 'thôi', 'thôi_việc', 'thúng_thắng', 'thương_ôi', 'thường', 'thường_bị', 'thường_hay', 'thường_khi', 'thường_số', 'thường_sự', 'thường_thôi', 'thường_thường', 'thường_tính', 'thường_tại', 'thường_xuất_hiện', 'thường_đến', 'thảo_hèn', 'thảo_nào', 'thấp', 'thấp_cơ', 'thấp_thỏm', 'thấp_xuống', 'thấy', 'thấy_tháng', 'thẩy', 'thậm', 'thậm_chí', 'thậm_cấp', 'thậm_từ', 'thật', 'thật_chắc', 'thật_là', 'thật_lực', 'thật_quả', 'thật_ra', 'thật_sự', 'thật_thà', 'thật_tốt', 'thật_vậy', 'thế', 'thế_chuẩn_bị', 'thế_là', 'thế_lại', 'thế_mà', 'thế_nào', 'thế_nên', 'thế_ra', 'thế_sự', 'thế_thì', 'thế_thôi', 'thế_thường', 'thế_thế', 'thế_à', 'thế_đó', 'thếch', 'thỉnh_thoảng', 'thỏm', 'thốc', 'thốc_tháo', 'thốt', 'thốt_nhiên', 'thốt_nói', 'thốt_thôi', 'thộc', 'thời_gian', 'thời_gian_sử_dụng', 'thời_gian_tính', 'thời_điểm', 'thục_mạng', 'thứ', 'thứ_bản', 'thứ_đến', 'thửa', 'thực_hiện', 'thực_hiện_đúng', 'thực_ra', 'thực_sự', 'thực_tế', 'thực_vậy', 'tin', 'tin_thêm', 'tin_vào', 'tiếp_theo', 'tiếp_tục', 'tiếp_đó', 'tiện_thể', 'toà', 'toé_khói', 'toẹt', 'trong', 'trong_khi', 'trong_lúc', 'trong_mình', 'trong_ngoài', 'trong_này', 'trong_số', 'trong_vùng', 'trong_đó', 'trong_ấy', 'tránh', 'tránh_khỏi', 'tránh_ra', 'tránh_tình_trạng', 'tránh_xa', 'trên', 'trên_bộ', 'trên_dưới', 'trước', 'trước_hết', 'trước_khi', 'trước_kia', 'trước_nay', 'trước_ngày', 'trước_nhất', 'trước_sau', 'trước_tiên', 'trước_tuổi', 'trước_đây', 'trước_đó', 'trả', 'trả_của', 'trả_lại', 'trả_ngay', 'trả_trước', 'trếu_tráo', 'trển', 'trệt', 'trệu_trạo', 'trỏng', 'trời_đất_ơi', 'trở_thành', 'trừ_phi', 'trực_tiếp', 'trực_tiếp_làm', 'tuy', 'tuy_có', 'tuy_là', 'tuy_nhiên', 'tuy_rằng', 'tuy_thế', 'tuy_vậy', 'tuy_đã', 'tuyệt_nhiên', 'tuần_tự', 'tuốt_luốt', 'tuốt_tuồn_tuột', 'tuốt_tuột', 'tuổi', 'tuổi_cả', 'tuổi_tôi', 'tà_tà', 'tên', 'tên_chính', 'tên_cái', 'tên_họ', 'tên_tự', 'tênh', 'tênh_tênh', 'tìm', 'tìm_bạn', 'tìm_cách', 'tìm_hiểu', 'tìm_ra', 'tìm_việc', 'tình_trạng', 'tính', 'tính_cách', 'tính_căn', 'tính_người', 'tính_phỏng', 'tính_từ', 'tít_mù', 'tò_te', 'tôi', 'tôi_con', 'tông_tốc', 'tù_tì', 'tăm_tắp', 'tăng', 'tăng_chúng', 'tăng_cấp', 'tăng_giảm', 'tăng_thêm', 'tăng_thế', 'tại', 'tại_lòng', 'tại_nơi', 'tại_sao', 'tại_tôi', 'tại_vì', 'tại_đâu', 'tại_đây', 'tại_đó', 'tạo', 'tạo_cơ_hội', 'tạo_nên', 'tạo_ra', 'tạo_ý', 'tạo_điều_kiện', 'tấm', 'tấm_bản', 'tấm_các', 'tấn', 'tấn_tới', 'tất_cả', 'tất_cả_bao_nhiêu', 'tất_thảy', 'tất_tần_tật', 'tất_tật', 'tập_trung', 'tắp', 'tắp_lự', 'tắp_tắp', 'tọt', 'tỏ_ra', 'tỏ_vẻ', 'tốc_tả', 'tối_ư', 'tốt', 'tốt_bạn', 'tốt_bộ', 'tốt_hơn', 'tốt_mối', 'tốt_ngày', 'tột', 'tột_cùng', 'tớ', 'tới', 'tới_gần', 'tới_mức', 'tới_nơi', 'tới_thì', 'tức_thì', 'tức_tốc', 'từ', 'từ_căn', 'từ_giờ', 'từ_khi', 'từ_loại', 'từ_nay', 'từ_thế', 'từ_tính', 'từ_tại', 'từ_từ', 'từ_ái', 'từ_điều', 'từ_đó', 'từ_ấy', 'từng', 'từng_cái', 'từng_giờ', 'từng_nhà', 'từng_phần', 'từng_thời_gian', 'từng_đơn_vị', 'từng_ấy', 'tự', 'tự_cao', 'tự_khi', 'tự_lượng', 'tự_tính', 'tự_tạo', 'tự_vì', 'tự_ý', 'tự_ăn', 'tựu_trung', 'veo', 'veo_veo', 'việc', 'việc_gì', 'vung_thiên_địa', 'vung_tàn_tán', 'vung_tán_tàn', 'và', 'vài', 'vài_ba', 'vài_người', 'vài_nhà', 'vài_nơi', 'vài_tên', 'vài_điều', 'vào', 'vào_gặp', 'vào_khoảng', 'vào_lúc', 'vào_vùng', 'vào_đến', 'vâng', 'vâng_chịu', 'vâng_dạ', 'vâng_vâng', 'vâng_ý', 'vèo', 'vèo_vèo', 'vì', 'vì_chưng', 'vì_rằng', 'vì_sao', 'vì_thế', 'vì_vậy', 'ví_bằng', 'ví_dù', 'ví_phỏng', 'ví_thử', 'vô_hình_trung', 'vô_kể', 'vô_luận', 'vô_vàn', 'vùng', 'vùng_lên', 'vùng_nước', 'văng_tê', 'vượt', 'vượt_khỏi', 'vượt_quá', 'vạn_nhất', 'vả_chăng', 'vả_lại', 'vấn_đề', 'vấn_đề_quan_trọng', 'vẫn', 'vẫn_thế', 'vậy', 'vậy_là', 'vậy_mà', 'vậy_nên', 'vậy_ra', 'vậy_thì', 'vậy_ư', 'về', 'về_không', 'về_nước', 'về_phần', 'về_sau', 'về_tay', 'vị_trí', 'vị_tất', 'vốn_dĩ', 'với', 'với_lại', 'với_nhau', 'vở', 'vụt', 'vừa', 'vừa_khi', 'vừa_lúc', 'vừa_mới', 'vừa_qua', 'vừa_rồi', 'vừa_vừa', 'xa', 'xa_cách', 'xa_gần', 'xa_nhà', 'xa_tanh', 'xa_tắp', 'xa_xa', 'xa_xả', 'xem', 'xem_lại', 'xem_ra', 'xem_số', 'xin', 'xin_gặp', 'xin_vâng', 'xiết_bao', 'xon_xón', 'xoành_xoạch', 'xoét', 'xoẳn', 'xoẹt', 'xuất_hiện', 'xuất_kì_bất_ý', 'xuất_kỳ_bất_ý', 'xuể', 'xuống', 'xăm_xúi', 'xăm_xăm', 'xăm_xắm', 'xảy_ra', 'xềnh_xệch', 'xệp', 'xử_lý', 'yêu_cầu', 'à', 'à_này', 'à_ơi', 'ào', 'ào_vào', 'ào_ào', 'á', 'á_à', 'ái', 'ái_chà', 'ái_dà', 'áng', 'áng_như', 'âu_là', 'ít', 'ít_biết', 'ít_có', 'ít_hơn', 'ít_khi', 'ít_lâu', 'ít_nhiều', 'ít_nhất', 'ít_nữa', 'ít_quá', 'ít_ra', 'ít_thôi', 'ít_thấy', 'ô_hay', 'ô_hô', 'ô_kê', 'ô_kìa', 'ôi_chao', 'ôi_thôi', 'ông', 'ông_nhỏ', 'ông_tạo', 'ông_từ', 'ông_ấy', 'ông_ổng', 'úi', 'úi_chà', 'úi_dào', 'ý', 'ý_chừng', 'ý_da', 'ý_hoặc', 'ăn', 'ăn_chung', 'ăn_chắc', 'ăn_chịu', 'ăn_cuộc', 'ăn_hết', 'ăn_hỏi', 'ăn_làm', 'ăn_người', 'ăn_ngồi', 'ăn_quá', 'ăn_riêng', 'ăn_sáng', 'ăn_tay', 'ăn_trên', 'ăn_về', 'đang', 'đang_tay', 'đang_thì', 'điều', 'điều_gì', 'điều_kiện', 'điểm', 'điểm_chính', 'điểm_gặp', 'điểm_đầu_tiên', 'đành_đạch', 'đáng', 'đáng_kể', 'đáng_lí', 'đáng_lý', 'đáng_lẽ', 'đáng_số', 'đánh_giá', 'đánh_đùng', 'đáo_để', 'đâu', 'đâu_có', 'đâu_cũng', 'đâu_như', 'đâu_nào', 'đâu_phải', 'đâu_đâu', 'đâu_đây', 'đâu_đó', 'đây', 'đây_này', 'đây_rồi', 'đây_đó', 'đã', 'đã_hay', 'đã_không', 'đã_là', 'đã_lâu', 'đã_thế', 'đã_vậy', 'đã_đủ', 'đó', 'đó_đây', 'đúng', 'đúng_ngày', 'đúng_ra', 'đúng_tuổi', 'đúng_với', 'đơn_vị', 'đưa', 'đưa_cho', 'đưa_chuyện', 'đưa_em', 'đưa_ra', 'đưa_tay', 'đưa_tin', 'đưa_tới', 'đưa_vào', 'đưa_về', 'đưa_xuống', 'đưa_đến', 'được', 'được_cái', 'được_lời', 'được_nước', 'được_tin', 'đại_loại', 'đại_nhân', 'đại_phàm', 'đại_để', 'đạt', 'đảm_bảo', 'đầu_tiên', 'đầy', 'đầy_năm', 'đầy_phè', 'đầy_tuổi', 'đặc_biệt', 'đặt', 'đặt_làm', 'đặt_mình', 'đặt_mức', 'đặt_ra', 'đặt_trước', 'đặt_để', 'đến', 'đến_bao_giờ', 'đến_cùng', 'đến_cùng_cực', 'đến_cả', 'đến_giờ', 'đến_gần', 'đến_hay', 'đến_khi', 'đến_lúc', 'đến_lời', 'đến_nay', 'đến_ngày', 'đến_nơi', 'đến_nỗi', 'đến_thì', 'đến_thế', 'đến_tuổi', 'đến_xem', 'đến_điều', 'đến_đâu', 'đều', 'đều_bước', 'đều_nhau', 'đều_đều', 'để', 'để_cho', 'để_giống', 'để_không', 'để_lòng', 'để_lại', 'để_mà', 'để_phần', 'để_được', 'để_đến_nỗi', 'đối_với', 'đồng_thời', 'đủ', 'đủ_dùng', 'đủ_nơi', 'đủ_số', 'đủ_điều', 'đủ_điểm', 'ơ', 'ơ_hay', 'ơ_kìa', 'ơi', 'ơi_là', 'ư', 'ạ', 'ạ_ơi', 'ấy', 'ấy_là', 'ầu_ơ', 'ắt', 'ắt_hẳn', 'ắt_là', 'ắt_phải', 'ắt_thật', 'ối_dào', 'ối_giời', 'ối_giời_ơi', 'ồ', 'ồ_ồ', 'ổng', 'ớ', 'ớ_này', 'ờ', 'ờ_ờ', 'ở', 'ở_lại', 'ở_như', 'ở_nhờ', 'ở_năm', 'ở_trên', 'ở_vào', 'ở_đây', 'ở_đó', 'ở_được', 'ủa', 'ứ_hự', 'ứ_ừ', 'ừ', 'ừ_nhé', 'ừ_thì', 'ừ_ào', 'ừ_ừ', 'ử']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Với bài toán nhận diện cảm xúc trong văn bản, điều quan trọng chính là lọc được các từ quan trọng, giúp ta suy được ra sắc thái của câu.\n",
        "\n",
        "Chúng ta sẽ xây dựng từ điển để lưu lại những từ quan trọng đó. Từ điển sẽ còn giúp ích rất lớn cho chúng ta không chỉ ở quá trình huấn luyện, mà còn ở quá trình đoán nhận"
      ],
      "metadata": {
        "id": "UbOy_V715Dly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def docs_to_words(doc, tokenize=False):\n",
        "  # token hoa cac file\n",
        "  w = doc.translate(str.maketrans('', '', string.punctuation.replace('_', ''))).lower()\n",
        "  if (tokenize):\n",
        "    w = rdrsegment.segmentRawSentences(tokenizer, w)\n",
        "  tokens = w.split()\n",
        "  # loai bo cac hu tu\n",
        "  tokens = [w for w in tokens if not w in stop_words]\n",
        "  # loai bo cac thanh phan chua ky tu khong phai chu cai\n",
        "  # thay the dau _ bang to hop cac phim khong co trong tieng Viet\n",
        "  tokens = [w.replace(\"_\", \"ZWJ\") for w in tokens]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  tokens = [w.replace(\"ZWJ\", \"_\") for w in tokens]\n",
        "  # lay nhung token co nhieu hon 1 ky tu\n",
        "  tokens = [word for word in tokens if len(word) > 1]\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "AYCOuc46xD8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = load_text(\"/content/drive/MyDrive/Dataset_Sentiment_Analysis/dataset/test/neg/29.txt\")\n",
        "print(docs_to_words(d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsV5CyD50fRm",
        "outputId": "14cdc533-b412-4ead-e14f-edfd1d88372e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['quán', 'comments', 'khen', 'chỗ', 'tối', 'hôm_qua', 'rủ', 'mấy', 'đồng_nghiệp', 'thử', 'cảm_nhận', 'quán', 'bàn_ghế', 'sạch_sẽ', 'không_gian', 'ấm_áp', 'vắng_tanh', 'phục_vụ', 'món', 'chậm', 'quán', 'giải_thích', 'đun', 'nóng', 'gọi', 'gọi', 'món', 'bò', 'ngâm', 'dấm', 'đợi', 'lẩu', 'bắp', 'bò', 'nhạt', 'khô', 'miếng', 'ngấm', 'miếng', 'tóm_lại', 'ngon', 'lẩu', 'ban_đầu', 'gọi', 'nồi', 'lẩu', 'cua_đồng', 'chủ', 'quán', 'gật_gật', 'phút', 'nhân_viên', 'quán', 'nồi', 'lẩu', 'bếp', 'nồi', 'nồi', 'chủ', 'quán', 'xác_nhận', 'uh', 'nồi', 'lẩu', 'thịt', 'bò', 'úc', 'sườn', 'sụn', 'chả', 'rau_sống', 'bánh_đa', 'kèm', 'số_lượng', 'đồ_ăn', 'đắt', 'giá', 'tiền', 'nồi', 'lẩu', 'cua_đồng', 'lưng_lửng', 'bụng', 'ngon', 'lẩu', 'chất_lượng', 'đồ_ăn', 'thất_vọng', 'ngon', 'ngất_trời', 'comments', 'nồi', 'lẩu', 'hết_sức', 'bình_thường', 'lẩu', 'nhạt_nhẽo', 'me', 'dở_hơi', 'đổ', 'đọc', 'comment', 'hy_vọng', 'chán', 'lẩu', 'bê', 'ngon', 'chốt', 'quán', 'món', 'lạc', 'rang', 'muối', 'ớt', 'ngon', 'giá_mà', 'nồi', 'lẩu', 'riêu', 'cua', 'quán', 'góc_hà_nội', 'hồ', 'thiền_quang', 'cảm_nhận', 'khác_biệt', 'rõ_rệt', 'một_trời_một_vực', 'lắm', 'chấm', 'quán', 'như_thế_này', 'đi', 'đồng_nghiệp', 'tiện', 'chụp', 'ảnh', 'ảnh', 'facebook', 'quán', 'nồi', 'lẩu', 'món', 'bò', 'ngâm', 'dấm', 'ảnh', 'hóa_đơn', 'chụp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm\n",
        "def vocabularize(filename, vocab, tokenize=False):\n",
        "\tdoc = load_text(filename)\n",
        "\ttokens = docs_to_words(doc, tokenize)\n",
        "\tvocab.update(tokens)\n",
        " \n",
        "# load all docs in a directory\n",
        "def process_docs_for_vocab(root_dir, vocab, tokenize=False):\n",
        "\t# walk through all files in the folder\n",
        "  directories = get_paths(root_dir)\n",
        "  length = len(directories)\n",
        "  count = 0\n",
        "  for filename in tqdm(directories):\n",
        "    vocabularize(filename, vocab, tokenize)"
      ],
      "metadata": {
        "id": "pl1nfOiPHq8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import string\n",
        "# define vocab\n",
        "vocab = Counter()\n",
        "vocab1 = Counter()\n",
        "vocab2 = Counter()\n",
        "# add all docs to vocab\n",
        "process_docs_for_vocab('/content/drive/MyDrive/Dataset_Sentiment_Analysis/dataset/test', vocab)\n",
        "process_docs_for_vocab('/content/drive/MyDrive/Dataset_Sentiment_Analysis/dataset/validate', vocab)\n",
        "process_docs_for_vocab('/content/drive/MyDrive/Dataset_Sentiment_Analysis/dataset/train/neg', vocab1)\n",
        "process_docs_for_vocab('/content/drive/MyDrive/Dataset_Sentiment_Analysis/dataset/train/pos', vocab2)\n",
        "vocab = vocab + vocab1 + vocab2\n",
        "# print the size of the vocab\n",
        "print(len(vocab))\n",
        "# print the top words in the vocab\n",
        "print(vocab.most_common(50))"
      ],
      "metadata": {
        "id": "Z6PALeEuI1_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ea7b85-3d00-4a16-9338-25f35401186b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10010/10010 [44:42<00:00,  3.73it/s]\n",
            "100%|██████████| 10000/10000 [44:04<00:00,  3.78it/s]\n",
            "100%|██████████| 15000/15000 [05:13<00:00, 47.80it/s] \n",
            "100%|██████████| 15008/15008 [04:59<00:00, 50.03it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41874\n",
            "[('quán', 55439), ('ngon', 41634), ('món', 28541), ('đi', 26720), ('ko', 26303), ('nhân_viên', 22479), ('uống', 18029), ('phục_vụ', 17359), ('hơi', 15920), ('bánh', 15256), ('lắm', 14587), ('giá', 14294), ('gọi', 13992), ('không_gian', 13548), ('trà', 12983), ('ng', 11764), ('mấy', 10593), ('vị', 10299), ('chỗ', 9863), ('thử', 9825), ('đồ_ăn', 9592), ('đẹp', 9256), ('kem', 8904), ('đồ', 8551), ('xe', 8357), ('đông', 8135), ('bàn', 8028), ('thịt', 7921), ('ghé', 7701), ('đc', 7590), ('mua', 7122), ('tiền', 6966), ('ly', 6873), ('nướng', 6787), ('nhiệt_tình', 6742), ('sữa', 6614), ('nh', 6607), ('chất_lượng', 6532), ('rẻ', 6466), ('bò', 6347), ('gà', 6307), ('giá_cả', 6162), ('thơm', 5933), ('cơm', 5756), ('kêu', 5679), ('xong', 5674), ('chủ', 5394), ('ok', 5304), ('la', 5159), ('dễ_thương', 5001)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta sẽ lọc ra những từ xuất hiện ít nhất 2 lần, rồi lưu lại vào file"
      ],
      "metadata": {
        "id": "ny0faSOUace6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep tokens with a min occurrence\n",
        "min_occurrence = 2\n",
        "tokens = [k for k,c in vocab.items() if c >= min_occurrence]\n",
        "\n",
        "def save_list(lines, filename):\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n",
        " \n",
        "# save tokens to a vocabulary file\n",
        "save_list(tokens, '/content/drive/MyDrive/Dataset_Sentiment_Analysis/vocab.txt')"
      ],
      "metadata": {
        "id": "wJ8C-RIdOHzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_filename = '/content/drive/MyDrive/Dataset_Sentiment_Analysis/vocab.txt'\n",
        "vocab = load_text(vocab_filename)\n",
        "vocab = vocab.split()\n",
        "vocab = set(vocab)"
      ],
      "metadata": {
        "id": "TFgXPgt2zSB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Chuẩn bị dữ liệu để đưa vào mô hình học máy:"
      ],
      "metadata": {
        "id": "8JeiO-PxLDQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta sẽ nhập những thư viện cần thiết vào"
      ],
      "metadata": {
        "id": "NbN7OThJaimL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gRJ8Lp-qLCw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiếp theo, ta sẽ bắt đầu làm sạch dữ liệu trong dataset, và chỉ lấy những từ xuất hiện trong từ điển"
      ],
      "metadata": {
        "id": "p8IE6VbzaoNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_doc(doc, vocab, tokenize=False):\n",
        "  # token hoa cac file\n",
        "  w = doc.translate(str.maketrans('', '', string.punctuation.replace('_', ''))).lower()\n",
        "  if (tokenize):\n",
        "    w = rdrsegment.segmentRawSentences(tokenizer, w)\n",
        "  tokens = w.split()\n",
        "  # lay nhung token co nhieu hon 1 ky tu\n",
        "  tokens = [w for w in tokens if w in vocab]\n",
        "  tokens = ' '.join(tokens)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "rOzNj6ZIRevB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta sẽ xuất dataset dưới dạng list các string."
      ],
      "metadata": {
        "id": "2fa_caFUa3VC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_dataset(root_dir, vocab, tokenize=False):\n",
        "\t# walk through all files in the folder\n",
        "  documents = list()\n",
        "  directories = get_paths(root_dir)\n",
        "  length = len(directories)\n",
        "  for filename in tqdm(directories):\n",
        "    doc = load_text(filename)\n",
        "    tokens = clean_doc(doc, vocab)\n",
        "    documents.append(tokens)\n",
        "  return documents"
      ],
      "metadata": {
        "id": "s7PA0seiSE0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load all training reviews\n",
        "positive_docs = prep_dataset('/content/drive/MyDrive/Dataset_Sentiment_Analysis/dataset/train/pos', vocab)\n",
        "negative_docs = prep_dataset('/content/drive/MyDrive/Dataset_Sentiment_Analysis/dataset/train/neg', vocab)\n",
        "train_docs = negative_docs + positive_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O0Q7BlcS0-3",
        "outputId": "ab4ad898-d5c2-4eb7-875a-342b391a1e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15008/15008 [00:33<00:00, 444.79it/s]\n",
            "100%|██████████| 15000/15000 [00:33<00:00, 447.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VGjhxxk7VOhx",
        "outputId": "dcd89d8a-765c-4960-ad1d-14137350d976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'quán đồ nhật quán bình thuờng đắt món dừng tuơng đối giá lợi_thế duy_nhất quán khu_phố cổ nhà_thờ tiện ăn_uống đi_lại chẳng'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giờ, ta sẽ vector hóa các câu trong bộ dữ liệu train. \n",
        "\n",
        "Chúng ta sử dụng 2 hàm sau:\n",
        "\n",
        "fit_on_texts: Tạo ra một từ điển riêng cho mô hình học máy, index của từ điển này sẽ dựa trên tần suất xuất hiện của từ. Từ xuất hiện càng nhiều, index sẽ càng thấp. Index sẽ bắt đầu từ 1, index 0 được dành riêng để phục vụ padding. Mỗi một từ sẽ có một index riêng biệt.\n",
        "\n",
        "texts_to_sequences: chuyển các từ trong câu thành một chuỗi các số nguyên. Cách chuyển được dựa trên từ điển sinh ra từ hàm fit_on_texts."
      ],
      "metadata": {
        "id": "KgKBEsaTiDFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the tokenizer\n",
        "k_tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "# fit the tokenizer on the documents\n",
        "k_tokenizer.fit_on_texts(train_docs)"
      ],
      "metadata": {
        "id": "Rid8NgLcLj2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Các văn bản khác nhau sẽ có độ dài khác nhau. Ta sẽ cần chọn một độ dài hợp lý. Nếu để văn bản quá dài, chúng ta có thể tạo ra các vector thưa, khiến hiệu năng của máy học giảm. Nếu cắt văn bản quá ngắn, ta có thể sẽ cắt mất thông tin. Chính vì vậy, ta sẽ thử thống kê độ dài của văn bản. Biểu đồ bên dưới sẽ cho ta thấy phân bố dộ dài văn bản. "
      ],
      "metadata": {
        "id": "Z-caCZyujqCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sequence encode\n",
        "encoded_docs = k_tokenizer.texts_to_sequences(train_docs)"
      ],
      "metadata": {
        "id": "O-di9ygdMUQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "a = plt.figure(figsize=(15,10))\n",
        "x = [len(i) for i in encoded_docs]\n",
        "stat = Counter(x)\n",
        "X, Y = [x for x, y in stat.items()], [y for x, y in stat.items()]\n",
        "plt.scatter(X, Y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "3N81ACyf0hc4",
        "outputId": "d11ccd6e-e545-4b27-f5f5-6adc50488237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta thấy rằng các văn bản có độ tập trung lớn nhất trong khoảng từ 0 -> 150 từ. Ta sẽ chọn kích cỡ là 200. Nếu dài quá, ta sẽ cắt ngắn văn bản đi. Nếu ngắn quá, ta sẽ thêm padding vào cuối văn bản. Tất cả sẽ được thực hiện tự động thông qua hàm pad_sequences của Keras.\n",
        "\n",
        "Ta cũng sẽ làm tương tự với tập dữ liệu test"
      ],
      "metadata": {
        "id": "WO-Canfpkks6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sequence encode\n",
        "encoded_docs = k_tokenizer.texts_to_sequences(train_docs)\n",
        "# pad sequences\n",
        "# max_length = max([len(s.split()) for s in train_docs]) #200\n",
        "max_length = 200\n",
        "Xtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "# define training labels\n",
        "size_neg = len(negative_docs)\n",
        "size_pos = len(positive_docs)\n",
        "ytrain = np.array([0 for _ in range(size_neg)] + [1 for _ in range(size_pos)])"
      ],
      "metadata": {
        "id": "TXgFLme1kipO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load all test reviews\n",
        "positive_test = prep_dataset('/content/drive/MyDrive/Dataset_Sentiment_Analysis/dataset/test/pos', vocab)\n",
        "negative_test = prep_dataset('/content/drive/MyDrive/Dataset_Sentiment_Analysis/dataset/test/neg', vocab)\n",
        "test_docs = negative_test + positive_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVpMJNetT9yC",
        "outputId": "49094680-0244-4a25-d010-95eff46a6950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:11<00:00, 444.49it/s]\n",
            "100%|██████████| 5010/5010 [00:11<00:00, 453.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sequence encode\n",
        "encoded_docs = k_tokenizer.texts_to_sequences(test_docs)\n",
        "# pad sequences\n",
        "Xtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "# define test labels\n",
        "ytest = np.array([0 for _ in range(len(negative_test))] + [1 for _ in range(len(positive_test))])"
      ],
      "metadata": {
        "id": "QX76DFSLUOXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta định nghĩa vocab_size, cũng chính là độ lớn của vocab thu được từ hàm fit_to_texts."
      ],
      "metadata": {
        "id": "4s0tCUorln_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define vocabulary size (largest integer value)\n",
        "vocab_size = len(k_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "0nKVvAHCVmqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta định nghĩa mô hình học máy và thực hiện huấn luyện. Mạng của chúng ta sẽ khá đơn giản, gồm 3 lớp: Một lớp Embedding, một lớp LSTM và một lớp FC để đoán nhận. Độ chính xác của mô hình này sau 70 epochs là 85%."
      ],
      "metadata": {
        "id": "RW-dvbzElsrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "model1 = Sequential()\n",
        "#model1.add(embedding_layer)\n",
        "model1.add(Embedding(vocab_size, 20)) #The embedding layer\n",
        "model1.add(LSTM(15,dropout=0.3)) #Our LSTM layer\n",
        "model1.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "\n",
        "model1.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model1.fit(Xtrain, ytrain, epochs=70,validation_data=(Xtest, ytest),callbacks=[checkpoint1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H_GixtYg0NM",
        "outputId": "c44030e2-595a-4000-9273-ff92fb0d9c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.4967\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50050, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 36s 36ms/step - loss: 0.6934 - accuracy: 0.4969 - val_loss: 0.6933 - val_accuracy: 0.5005\n",
            "Epoch 2/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5006\n",
            "Epoch 2: val_accuracy improved from 0.50050 to 0.50070, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.6933 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5007\n",
            "Epoch 3/70\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.6629\n",
            "Epoch 3: val_accuracy improved from 0.50070 to 0.67313, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.6272 - accuracy: 0.6629 - val_loss: 0.6151 - val_accuracy: 0.6731\n",
            "Epoch 4/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.6130 - accuracy: 0.6797\n",
            "Epoch 4: val_accuracy did not improve from 0.67313\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.6129 - accuracy: 0.6798 - val_loss: 0.6173 - val_accuracy: 0.6719\n",
            "Epoch 5/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.6205 - accuracy: 0.6659\n",
            "Epoch 5: val_accuracy improved from 0.67313 to 0.68811, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.6206 - accuracy: 0.6658 - val_loss: 0.6079 - val_accuracy: 0.6881\n",
            "Epoch 6/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.6155 - accuracy: 0.6683\n",
            "Epoch 6: val_accuracy did not improve from 0.68811\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.6155 - accuracy: 0.6682 - val_loss: 0.6158 - val_accuracy: 0.6649\n",
            "Epoch 7/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.6111 - accuracy: 0.6671\n",
            "Epoch 7: val_accuracy did not improve from 0.68811\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.6111 - accuracy: 0.6671 - val_loss: 0.6050 - val_accuracy: 0.6709\n",
            "Epoch 8/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5823 - accuracy: 0.6878\n",
            "Epoch 8: val_accuracy improved from 0.68811 to 0.71798, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5823 - accuracy: 0.6877 - val_loss: 0.5669 - val_accuracy: 0.7180\n",
            "Epoch 9/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5693 - accuracy: 0.7042\n",
            "Epoch 9: val_accuracy did not improve from 0.71798\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5692 - accuracy: 0.7042 - val_loss: 0.5854 - val_accuracy: 0.6770\n",
            "Epoch 10/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5740 - accuracy: 0.6907\n",
            "Epoch 10: val_accuracy did not improve from 0.71798\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5741 - accuracy: 0.6906 - val_loss: 0.5647 - val_accuracy: 0.7027\n",
            "Epoch 11/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5596 - accuracy: 0.7156\n",
            "Epoch 11: val_accuracy improved from 0.71798 to 0.74875, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5595 - accuracy: 0.7156 - val_loss: 0.5430 - val_accuracy: 0.7488\n",
            "Epoch 12/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5483 - accuracy: 0.7291\n",
            "Epoch 12: val_accuracy did not improve from 0.74875\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5483 - accuracy: 0.7291 - val_loss: 0.6001 - val_accuracy: 0.6676\n",
            "Epoch 13/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.7115\n",
            "Epoch 13: val_accuracy did not improve from 0.74875\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5573 - accuracy: 0.7115 - val_loss: 0.5536 - val_accuracy: 0.7265\n",
            "Epoch 14/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5444 - accuracy: 0.7275\n",
            "Epoch 14: val_accuracy did not improve from 0.74875\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5442 - accuracy: 0.7276 - val_loss: 0.5588 - val_accuracy: 0.7392\n",
            "Epoch 15/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5288 - accuracy: 0.7424\n",
            "Epoch 15: val_accuracy did not improve from 0.74875\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5288 - accuracy: 0.7424 - val_loss: 0.5353 - val_accuracy: 0.7378\n",
            "Epoch 16/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5275 - accuracy: 0.7499\n",
            "Epoch 16: val_accuracy improved from 0.74875 to 0.75205, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5275 - accuracy: 0.7498 - val_loss: 0.5162 - val_accuracy: 0.7520\n",
            "Epoch 17/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5237 - accuracy: 0.7532\n",
            "Epoch 17: val_accuracy improved from 0.75205 to 0.76354, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.5238 - accuracy: 0.7531 - val_loss: 0.5264 - val_accuracy: 0.7635\n",
            "Epoch 18/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5187 - accuracy: 0.7623\n",
            "Epoch 18: val_accuracy did not improve from 0.76354\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.5187 - accuracy: 0.7623 - val_loss: 0.5197 - val_accuracy: 0.7589\n",
            "Epoch 19/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5100 - accuracy: 0.7636\n",
            "Epoch 19: val_accuracy improved from 0.76354 to 0.76733, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5100 - accuracy: 0.7636 - val_loss: 0.5089 - val_accuracy: 0.7673\n",
            "Epoch 20/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5057 - accuracy: 0.7685\n",
            "Epoch 20: val_accuracy did not improve from 0.76733\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5055 - accuracy: 0.7686 - val_loss: 0.5235 - val_accuracy: 0.7582\n",
            "Epoch 21/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5065 - accuracy: 0.7706\n",
            "Epoch 21: val_accuracy improved from 0.76733 to 0.77043, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5065 - accuracy: 0.7706 - val_loss: 0.5152 - val_accuracy: 0.7704\n",
            "Epoch 22/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5081 - accuracy: 0.7692\n",
            "Epoch 22: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5081 - accuracy: 0.7692 - val_loss: 0.5053 - val_accuracy: 0.7703\n",
            "Epoch 23/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5089 - accuracy: 0.7647\n",
            "Epoch 23: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5088 - accuracy: 0.7647 - val_loss: 0.5221 - val_accuracy: 0.7562\n",
            "Epoch 24/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5063 - accuracy: 0.7663\n",
            "Epoch 24: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5062 - accuracy: 0.7664 - val_loss: 0.5207 - val_accuracy: 0.7555\n",
            "Epoch 25/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5340 - accuracy: 0.7420\n",
            "Epoch 25: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5338 - accuracy: 0.7421 - val_loss: 0.5370 - val_accuracy: 0.7569\n",
            "Epoch 26/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5199 - accuracy: 0.7528\n",
            "Epoch 26: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5199 - accuracy: 0.7528 - val_loss: 0.5710 - val_accuracy: 0.6844\n",
            "Epoch 27/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5173 - accuracy: 0.7565\n",
            "Epoch 27: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5173 - accuracy: 0.7565 - val_loss: 0.5159 - val_accuracy: 0.7650\n",
            "Epoch 28/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5264 - accuracy: 0.7590\n",
            "Epoch 28: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5263 - accuracy: 0.7591 - val_loss: 0.5267 - val_accuracy: 0.7525\n",
            "Epoch 29/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5429 - accuracy: 0.7456\n",
            "Epoch 29: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5429 - accuracy: 0.7456 - val_loss: 0.5533 - val_accuracy: 0.7568\n",
            "Epoch 30/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5146 - accuracy: 0.7631\n",
            "Epoch 30: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.5146 - accuracy: 0.7631 - val_loss: 0.5191 - val_accuracy: 0.7596\n",
            "Epoch 31/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5144 - accuracy: 0.7678\n",
            "Epoch 31: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.5143 - accuracy: 0.7679 - val_loss: 0.5606 - val_accuracy: 0.7391\n",
            "Epoch 32/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5241 - accuracy: 0.7558\n",
            "Epoch 32: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.5242 - accuracy: 0.7558 - val_loss: 0.5354 - val_accuracy: 0.7470\n",
            "Epoch 33/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5279 - accuracy: 0.7580\n",
            "Epoch 33: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.5279 - accuracy: 0.7580 - val_loss: 0.5636 - val_accuracy: 0.7420\n",
            "Epoch 34/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5221 - accuracy: 0.7685\n",
            "Epoch 34: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.5220 - accuracy: 0.7685 - val_loss: 0.5110 - val_accuracy: 0.7567\n",
            "Epoch 35/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.4940 - accuracy: 0.7639\n",
            "Epoch 35: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.4939 - accuracy: 0.7640 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 36/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5148 - accuracy: 0.7545\n",
            "Epoch 36: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.5147 - accuracy: 0.7545 - val_loss: 0.5235 - val_accuracy: 0.7598\n",
            "Epoch 37/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5286 - accuracy: 0.7467\n",
            "Epoch 37: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5287 - accuracy: 0.7467 - val_loss: 0.5319 - val_accuracy: 0.7428\n",
            "Epoch 38/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5107 - accuracy: 0.7590\n",
            "Epoch 38: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5107 - accuracy: 0.7590 - val_loss: 0.5139 - val_accuracy: 0.7597\n",
            "Epoch 39/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5032 - accuracy: 0.7561\n",
            "Epoch 39: val_accuracy did not improve from 0.77043\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.5032 - accuracy: 0.7562 - val_loss: 0.5330 - val_accuracy: 0.7549\n",
            "Epoch 40/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5255 - accuracy: 0.7593\n",
            "Epoch 40: val_accuracy improved from 0.77043 to 0.77982, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.5254 - accuracy: 0.7593 - val_loss: 0.5154 - val_accuracy: 0.7798\n",
            "Epoch 41/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5108 - accuracy: 0.7806\n",
            "Epoch 41: val_accuracy improved from 0.77982 to 0.78591, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.5107 - accuracy: 0.7807 - val_loss: 0.5196 - val_accuracy: 0.7859\n",
            "Epoch 42/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5092 - accuracy: 0.7809\n",
            "Epoch 42: val_accuracy did not improve from 0.78591\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.5092 - accuracy: 0.7809 - val_loss: 0.5188 - val_accuracy: 0.7834\n",
            "Epoch 43/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.7743\n",
            "Epoch 43: val_accuracy did not improve from 0.78591\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.5058 - accuracy: 0.7744 - val_loss: 0.4999 - val_accuracy: 0.7659\n",
            "Epoch 44/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5054 - accuracy: 0.7563\n",
            "Epoch 44: val_accuracy did not improve from 0.78591\n",
            "938/938 [==============================] - 34s 36ms/step - loss: 0.5054 - accuracy: 0.7563 - val_loss: 0.5320 - val_accuracy: 0.7246\n",
            "Epoch 45/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.4922 - accuracy: 0.7513\n",
            "Epoch 45: val_accuracy did not improve from 0.78591\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.4922 - accuracy: 0.7513 - val_loss: 0.4895 - val_accuracy: 0.7404\n",
            "Epoch 46/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5005 - accuracy: 0.7580\n",
            "Epoch 46: val_accuracy did not improve from 0.78591\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5007 - accuracy: 0.7580 - val_loss: 0.5309 - val_accuracy: 0.7771\n",
            "Epoch 47/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.5167 - accuracy: 0.7659\n",
            "Epoch 47: val_accuracy did not improve from 0.78591\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.5168 - accuracy: 0.7659 - val_loss: 0.5015 - val_accuracy: 0.7639\n",
            "Epoch 48/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.4793 - accuracy: 0.7703\n",
            "Epoch 48: val_accuracy did not improve from 0.78591\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.4792 - accuracy: 0.7704 - val_loss: 0.4939 - val_accuracy: 0.7822\n",
            "Epoch 49/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.4872 - accuracy: 0.7825\n",
            "Epoch 49: val_accuracy did not improve from 0.78591\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.4871 - accuracy: 0.7825 - val_loss: 0.5285 - val_accuracy: 0.7819\n",
            "Epoch 50/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.4890 - accuracy: 0.7809\n",
            "Epoch 50: val_accuracy improved from 0.78591 to 0.78621, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.4890 - accuracy: 0.7809 - val_loss: 0.4886 - val_accuracy: 0.7862\n",
            "Epoch 51/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.4949 - accuracy: 0.7766\n",
            "Epoch 51: val_accuracy improved from 0.78621 to 0.79520, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.4949 - accuracy: 0.7767 - val_loss: 0.4785 - val_accuracy: 0.7952\n",
            "Epoch 52/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.4749 - accuracy: 0.7733\n",
            "Epoch 52: val_accuracy improved from 0.79520 to 0.81469, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.4749 - accuracy: 0.7734 - val_loss: 0.4350 - val_accuracy: 0.8147\n",
            "Epoch 53/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.4320 - accuracy: 0.8159\n",
            "Epoch 53: val_accuracy did not improve from 0.81469\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.4319 - accuracy: 0.8160 - val_loss: 0.4322 - val_accuracy: 0.8129\n",
            "Epoch 54/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.4130 - accuracy: 0.8249\n",
            "Epoch 54: val_accuracy improved from 0.81469 to 0.83187, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.4129 - accuracy: 0.8249 - val_loss: 0.4040 - val_accuracy: 0.8319\n",
            "Epoch 55/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8350\n",
            "Epoch 55: val_accuracy improved from 0.83187 to 0.83706, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.3913 - accuracy: 0.8350 - val_loss: 0.3918 - val_accuracy: 0.8371\n",
            "Epoch 56/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3752 - accuracy: 0.8395\n",
            "Epoch 56: val_accuracy did not improve from 0.83706\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3752 - accuracy: 0.8395 - val_loss: 0.3811 - val_accuracy: 0.8342\n",
            "Epoch 57/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3689 - accuracy: 0.8406\n",
            "Epoch 57: val_accuracy improved from 0.83706 to 0.83906, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.3689 - accuracy: 0.8406 - val_loss: 0.3794 - val_accuracy: 0.8391\n",
            "Epoch 58/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3690 - accuracy: 0.8457\n",
            "Epoch 58: val_accuracy improved from 0.83906 to 0.84795, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3690 - accuracy: 0.8457 - val_loss: 0.3809 - val_accuracy: 0.8480\n",
            "Epoch 59/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3568 - accuracy: 0.8531\n",
            "Epoch 59: val_accuracy did not improve from 0.84795\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3570 - accuracy: 0.8530 - val_loss: 0.3880 - val_accuracy: 0.8397\n",
            "Epoch 60/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8545\n",
            "Epoch 60: val_accuracy did not improve from 0.84795\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3487 - accuracy: 0.8545 - val_loss: 0.3856 - val_accuracy: 0.8360\n",
            "Epoch 61/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3461 - accuracy: 0.8560\n",
            "Epoch 61: val_accuracy did not improve from 0.84795\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.3460 - accuracy: 0.8561 - val_loss: 0.3854 - val_accuracy: 0.8288\n",
            "Epoch 62/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3384 - accuracy: 0.8609\n",
            "Epoch 62: val_accuracy improved from 0.84795 to 0.85065, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3385 - accuracy: 0.8609 - val_loss: 0.3646 - val_accuracy: 0.8506\n",
            "Epoch 63/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3342 - accuracy: 0.8661\n",
            "Epoch 63: val_accuracy improved from 0.85065 to 0.85634, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3342 - accuracy: 0.8662 - val_loss: 0.3488 - val_accuracy: 0.8563\n",
            "Epoch 64/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3251 - accuracy: 0.8698\n",
            "Epoch 64: val_accuracy improved from 0.85634 to 0.85894, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.3252 - accuracy: 0.8697 - val_loss: 0.3455 - val_accuracy: 0.8589\n",
            "Epoch 65/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3166 - accuracy: 0.8744\n",
            "Epoch 65: val_accuracy did not improve from 0.85894\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3165 - accuracy: 0.8745 - val_loss: 0.3437 - val_accuracy: 0.8575\n",
            "Epoch 66/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3122 - accuracy: 0.8753\n",
            "Epoch 66: val_accuracy did not improve from 0.85894\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3123 - accuracy: 0.8753 - val_loss: 0.3505 - val_accuracy: 0.8568\n",
            "Epoch 67/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3091 - accuracy: 0.8781\n",
            "Epoch 67: val_accuracy improved from 0.85894 to 0.86124, saving model to best_model1.hdf5\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3094 - accuracy: 0.8779 - val_loss: 0.3441 - val_accuracy: 0.8612\n",
            "Epoch 68/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3057 - accuracy: 0.8801\n",
            "Epoch 68: val_accuracy did not improve from 0.86124\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3056 - accuracy: 0.8802 - val_loss: 0.3469 - val_accuracy: 0.8578\n",
            "Epoch 69/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3114 - accuracy: 0.8795\n",
            "Epoch 69: val_accuracy did not improve from 0.86124\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3114 - accuracy: 0.8795 - val_loss: 0.3703 - val_accuracy: 0.8565\n",
            "Epoch 70/70\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.8807\n",
            "Epoch 70: val_accuracy did not improve from 0.86124\n",
            "938/938 [==============================] - 33s 36ms/step - loss: 0.3049 - accuracy: 0.8807 - val_loss: 0.3535 - val_accuracy: 0.8612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta lưu và nạp mô hình lại dựa vào 2 đoạn code trên"
      ],
      "metadata": {
        "id": "uvU-gRXhvmJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"/content/drive/MyDrive/Dataset_Sentiment_Analysis/model/model1.h5\")"
      ],
      "metadata": {
        "id": "3fSQmquBEKVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model1 = tf.keras.models.load_model('/content/drive/MyDrive/Dataset_Sentiment_Analysis/model/model1.h5')"
      ],
      "metadata": {
        "id": "FHTxKHfIGZuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Thử nghiệm </h3>"
      ],
      "metadata": {
        "id": "tkhHsteTvrq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_string = 'Hôm nay mình đi ăn ở quán ABCZYX, đồ ăn rất ngon, phục vụ tận tình'\n",
        "test_array = [clean_doc(test_string, vocab, True)]\n",
        "encoded = k_tokenizer.texts_to_sequences(test_array)\n",
        "test = pad_sequences(encoded, maxlen=max_length, padding='post')\n",
        "predicted = model1.predict(test)\n",
        "print(predicted)\n",
        "if (predicted > 0.5): print('Positive')\n",
        "else: print('Negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xenP2QcIyqFr",
        "outputId": "5a8c0df2-995e-445c-f53a-0fa0dea7b51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.7290563]]\n",
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> <i> REFERENCES </i> </h1>\n",
        "\n",
        "[1] Tran. Nghia; Vietnamese Dataset, from Foody; https://github.com/congnghia0609/ntc-scv/tree/master/data\n",
        "\n",
        "[2] Pham. Vinh; Vietnamese-Word-Segmentation-Python; adapted from Nguyen. Dat, Nguyen. Dai, Dras. Mark, Johnson. Mark; A Fast and Accurate Vietnamese Word Segmenter;\n",
        "github.com/Sudo-VP/Vietnamese-Word-Segmentation-Python\n",
        "\n",
        "[3] Tran. Nghia, Le. Hung; Phân tích cảm xúc trong Tiếng Việt; https://streetcodevn.com/blog/sav\n",
        "\n",
        "[4] Tran. Nghia, Le. Hung; Cách tách từ cho tiếng Việt; https://streetcodevn.com/blog/vntok\n",
        "\n",
        "[5] Le. Duyet; Stop words; https://github.com/stopwords/vietnamese-stopwords\n",
        "\n",
        "[6] Virahonda. Sergio; An easy tutorial about Sentiment Analysis with Deep Learning and Keras; https://towardsdatascience.com/an-easy-tutorial-about-sentiment-analysis-with-deep-learning-and-keras-2bf52b9cba91\n",
        "\n",
        "[7] Sucky. Rashida; A Complete Step by Step Tutorial on Sentiment Analysis in Keras and Tensorflow; https://towardsdatascience.com/a-complete-step-by-step-tutorial-on-sentiment-analysis-in-keras-and-tensorflow-ea420cc8913f\n",
        "\n",
        "[8] Brownlee. Jason; Deep Convolutional Neural Network for Sentiment Analysis (Text Classification); https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n",
        "\n",
        "[9] Pham. Quang; Xây dựng mô hình không gian vector cho Tiếng Việt; https://viblo.asia/p/xay-dung-mo-hinh-khong-gian-vector-cho-tieng-viet-GrLZDXr2Zk0"
      ],
      "metadata": {
        "id": "9aUga3CwSRNt"
      }
    }
  ]
}